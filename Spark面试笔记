1,Spark消费Kafka,分布式情况下,如何保证信息的顺序?
    Kafka分布式的单位是Partition。如何保证消息有序,需要分几个情况讨论。
    a,使用一个Partition去存储数据,可以保证FIFO的顺序
    b,不同的Partition之间不能保证顺序。但是绝大多数据用户都可以通过message key来定义,因为同一个key
      的message可以保证只发送到同一个Partition。比如说key是userid,table row id等等，所以同一个user
      或者同一个record的消息永远只会发送到同一个Partition上,保证了同一个user或record的顺序

2,对于Spark中的数据倾斜问题你有什么好的方案？
    简单答案:避免数据源倾斜,调整并行度,使用自定义Partitioner,使用Map侧Join代替Reduce侧Join(内存表合并）
        给倾斜Key加上随机前缀

    什么是数据倾斜 数据倾斜指的是,并行处理的数据集中,某一部分的数据显著多于其他部分,从而使得该部分的处理
        速度成为整个数据集处理的瓶颈

    数据倾斜是如何造成的 在Spark中,同一个Stage的不同Partition可以并行处理，而具有依赖关系的不同stage之间
        是串行处理的。假设某个Spark Job分为Stage 0和Stage 1两个Stage,且Stage1依赖于Stage 0,那Stage 0完全
        处理结束之前不会处理Stage 1。而Stage 0可能包含 N个 Task,这N个Task可以并行进行,如果其中N-1个Task都
        在10秒内完成,而另外一个Task却耗时1分钟,那该Stage的总时间至少为1分钟。换句话说,一个Stage所耗的时间
        是由最慢的那个Task决定的。由于同一个Stage内的所有Task执行相同的计算,在排除不同计算节点计算能力差异
        的前提下,不同的Task之间耗时的差异主要由该Task所处理的数据量决定

    具体解决方案:
        1,调整并行度分散同一个Task的不同Key,Spark在做shuffle时,默认使用HashPartitioner对数据进行分区。如果
        并行度设置的不合适,可能造成大量不相同的key对应的数据分配到了同一个Task上,造成Task处理的数据远远大于
        其它Task,从而造成数据倾斜.如果调整shuffle的并行度,使得原本分配到同一个Task的不同key发配到不同Task上
        处理,则降低原Task所需处理的数据量,从而缓解数据倾斜问题造成的短板效应

        2,自定义Partitioner:使用自定义Partitioner(默认为HashPartitioner),将原本分配到同一个Task的不同key分配
        到不同的Task

        3,将Reduce side(侧)join转变为Map side(侧)join，通过Spark的Broadcasr机制,将Reduce侧Join转换为Map侧Join,
        避免shuffle从而完全消除shuffle带来的数据倾斜

        4,为skew的Key增加随机前/后缀 为数据量特别大的Key增加堆积前/后缀,使得原来的key相同的数据变为Key不相同的数据
        ,从而使倾斜的数据集分散到不同的Task中,彻底解决数据倾斜问题。数据处理完之后去除key的前缀进行二次计算

        5,大表随机添加N种随机前缀,小表扩大N倍,如果出现数据倾斜的Key比较多.直接对存在数据倾斜的数据集全部加上随机前缀，
        然后对另外一个不存在严重数据倾斜的数据集按照大表的随机前缀进行扩充（faltMap操作）,两个数据集join完之后去除
        前缀进行二次计算

3,你所理解的Spark的shuffle过程
    Spark shuffle处于一个宽依赖,可以实现类似混洗的功能,将相同的key分发到同一个reducer上进行处理

4,Spark有哪些聚合类的算子,我们应该尽量避免什么类型的算子
    尽量避免使用reduceByKey,Join，distinct，repartition等会进进行shuffle的算子,尽量使用map类的非
    shuffle算子.这样的话,没有shuffle操作或者仅有较少shuffle操作的Spark作业,可以大大减少开销

5,spark on yarn作业执行流程,yarn-client和yarn cluster有什么区别
    1,spark支持资源动态共享,运行于yarn的框架都共享一个集中配置好的资源池
    2,可以很方便的利用yarn的资源调度性来作分类,隔离以及优先级控制负载,拥有更灵活的调度策略
    3,yarn可以自由地选择executor数量
    4,yarn是唯一支持spark安全的集群管理器,使用yarn,spark可以运行于kerberized hadoop之上,在它们
    进程之间进行安全认证

    yarn-cilent和yarn cluster的异同 1,从广义上讲,yarn-cluster适用于生产环境.而yarn-client适用于
    交互和调试,也就是希望快速看到application的输出. 2,从深层的含义讲,yarn-cluster和yarn-client
    模式的区别其实就是Application Master进程的区别,yarn-cluster模式下,driver运行在AM中,它负责向
    yarn申请资源,并监督作业的运行状况.当用户提交作业之后,就可以换掉client,作业会继续在yarn上运行
    而yarn-client模式下，Application Master仅仅向yarn请求executor，Client会和请求的container通信
    来调度他们工作,client不能离开
6,spark为什么快,sparkSql一定比Hive快吗
    1,消除了冗余的HDFS读写,Hadoop每次shuffle操作后必须写到磁盘,而spark在shufle后不一定落盘,可以
    cache到内存中,以便迭代时使用.如果操作复杂有很多shuffle操作,那么Hadoop的读写IO时间会大大增加
    2,消除了冗余的MapReduce阶段,Hadoop的shuffle操作一定连着完整的MapReduce操作,冗余繁琐。而Spark
    基于RDD提供了丰富的算子操作,reduce产生的shuffle数据,可以缓存到内存中
    3,JVM的优化,Hadoop的每次操作,启动一个Task便会启动过一次JVM,基于进程的操作。而Spark每次MapReduce
    操作是基于线程的,只在启动Executor时启动一次JVM，内存的task操作是在线程复用。

    spark快不是绝对的,但是绝大多数spark都比hadoop计算要快,这主要得益于对mapreduce操作的优化以及对jvm使用的优化

7,RDD,DAG,Stage怎么理解?

    DAG Spark中使用DAG对RDD关系进行建模,描述RDD间的依赖关系

    RDD 弹性分布式数据集,一个RDD代表一个可以被分区的只读数据集.Rdd内部可以有许多分区(partition)
        每个分区拥有大量的记录(record)
        Rdd五个特征:1,dependencies:建立RDD的依赖关系(宽依赖,窄依赖)
                    2,partition:一个RDD会有若干个分区,分区的大小决定对这个RDD的计算粒度,每个RDD
                          的分区计算都在一个单独的任务中进行
                    3,preferedlications:按照移动数据不如移动计算原则,spark进行任务调度的时候,优先将
                          任务分配到数据块存储的位置
                    4,compute:Spark中的计算都是以分区为基本单位,compute函数只是对迭代器进行符合,并不保存
                          单次计算的结果
                    5,partitioner:只存在于(K,V)类型的RDD中,非(K,V)类型partitoner默认是None

8,RDD如何通过记录更新的方式容错
    1,数据检查点(checkpoint)
    2,记录更新,"血统"容错

9,宽依赖,窄依赖如何理解?
    窄依赖是一对一关系(Narrow Dependencies)
    宽依赖是多对一关系会发生shuffle操作 (Shuffle Dependecies)

10,Job和Task怎么理解
    Job Spark的action算子触发Job,表示一个执行任务
    Task 一个Stage内,最终的RDD有多少partition就会产生多少task

11,Spark血统的概念
    lineage表示的是rdd之间的依赖关系,当rdd的部分分区数据丢失时,它可以通过lineage获取足够的信息重新计算
    并恢复丢失的数据分区

12,Spark作业的提交流程是怎么样的
    1,spark-submit提交代码,执行new SparkContext(),在SparkContext里构造DAGScheduler和TaskScheduler
    2，TaskSheduler通过后台的一个进程连接Master,向Master注册Application
    3，Master接收到Application请求后,会使用相应的资源调度算法,在Worker上为这个Application启动多个Executor
    4，Executor启动后会反向注册给TaskScheduler,所有Executor都注册到Driver后,SparkContext结束初始化,接下来
       往下执行具体的代码逻辑
    5,每执行到一个Action,就会创建一个Job。Job会提交给DAGScheduler
    6,DAGScheduler会将Job划分为多个stage,然后每个stage创建一个TaskSet
    7,TaskScheduler会把每一个TaskSet里的Task提交到Executor上执行
    8,Executor上有线程池,每接收到一个Task,就用TaskRunner封装,然后从线程池里取出一个线程去执行这个Task
    （TaskRunner将我们编写的代码拷贝,反序列化,执行Task，每个Task执行RDD里的一个partition）

13,说说spark支持的3种集群管理器
    standalone模式:资源管理器是Master节点,调度策略相对单一,只支持先进先出,一个任务全部执行完之后才能释放所有资源
    yarn模式: 支持动态资源管理
    mesos:可以对集群中的资源做弹性管理(具体没有使用过)

14,说说Worker和Executor的异同
    Worker是指每个节点上启动的一个进程,负责本地节点,JPS可以看到Worker进程的运行,Executor是每个Spark程序在每个节点上启动的
    一个进程,专属于一个spark程序,与spark程序有相同的生命周期,负责spark在节点上启动task,管理内存和磁盘.如果一个节点上有多个
    spark程序,那么相应就会启动多个执行器

15,说说Spark的高可用和容错
    Spark应用程序执行过程中,一般存在以下失败执行情况:
        Driver进程宕机:driver运行机器宕机,driver程序运行过程中异常导致进程宕机
        Executor进程宕机:比如executor进程所在机器的worker宕机,Executor和Driver之间通信超时
        Task执行失败:Task任务执行线程执行过程中产生异常导致Task执行失败

    Driver进程宕机解决方案:
        1,运维监控机器是否存活,如果机器宕机,运维人员重启服务器及spark应用
        2,运维通过spark job的history服务,监控应用是否执行成功,如果执行失败,通知开发人员重启服务
        3,sparkStreaming中,重启spark应用后,可通过checkpointDir进行job数据恢复
    Executor进程宕机:
        选择一个worker节点重启Executor进程,Driver重新分配任务
    Task执行失败解决方案:
        1,spark程序会进行task重试机制,如果某个task失败重试次数超过3次(spark.task.maxFailures),如果超过
        4次,当前job执行失败
        2，如果RDD的lineage生命线特别长,此时某些task执行失败的恢复成本就会比较高,那么可以采用检查点(checkpoint)
        或者缓存(cache)的方式将数据冗余的保存下来,当检查点或缓存点之后的task出现异常的时候,可以直接从检查
        点重新构建lineage,可以减少执行开销

16,说说Spark如何实现序列化组件
    Java序列化
    在默认情况下，Spark采用Java的ObjectOutputStream序列化一个对象。该方式适用于所有实现了java.io.Serializable的类。通过继承java.io.Externalizable，你能进一步控制序列化的性能。Java序列化非常灵活，但是速度较慢，在某些情况下序列化的结果也比较大。
    Kryo序列化
    Spark也能使用Kryo（版本2）序列化对象。Kryo不但速度极快，而且产生的结果更为紧凑（通常能提高10倍）。Kryo的缺点是不支持所有类型，为了更好的性能，你需要提前注册程序中所使用的类（class）。
    Java的序列化比较简单，就和前面的一样，下面主要介绍Kryo序列化的使用。
    Kryo序列化怎么用？
    可以在创建SparkContext之前，通过调用System.setProperty("spark.serializer", "spark.KryoSerializer")，将序列化方式切换成Kryo。
    但是Kryo需要用户进行注册，这也是为什么Kryo不能成为Spark序列化默认方式的唯一原因，但是建议对于任何“网络密集型”（network-intensive)的应用，都采用这种方式进行序列化方式。
    Kryo文档描述了很多便于注册的高级选项，例如添加用户自定义的序列化代码。
    如果对象非常大，你还需要增加属性spark.kryoserializer.buffer.mb的值。该属性的默认值是32，但是该属性需要足够大以便能够容纳需要序列化的最大对象。
    最后，如果你不注册你的类，Kryo仍然可以工作，但是需要为了每一个对象保存其对应的全类名（full class name),这是非常浪费的。

17,SparkStreaming小文件问题
    使用 Spark Streaming 时，如果实时计算结果要写入到 HDFS，那么不可避免的会遇到一个问题，那就是在默认情况下会产生非常多的小文件，这是由 Spark Streaming 的微批处理模式和 DStream(RDD) 的分布式(partition)特性导致的，Spark Streaming 为每个 Partition 启动一个独立的线程（一个 task/partition 一个线程）来处理数据，一旦文件输出到 HDFS，那么这个文件流就关闭了，再来一个 batch 的 parttition 任务，就再使用一个新的文件流，那么假设，一个 batch 为10s，每个输出的 DStream 有32个 partition，那么一个小时产生的文件数将会达到(3600/10)*32=11520个之多。众多小文件带来的结果是有大量的文件元信息，比如文件的 location、文件大小、block number 等需要 NameNode 来维护，NameNode 会因此鸭梨山大。不管是什么格式的文件，parquet、text、JSON 或者 Avro，都会遇到这种小文件问题，这里讨论几种处理 Spark Streaming 小文件的典型方法。
    增加 batch 大小: 这种方法很容易理解，batch 越大，从外部接收的 event 就越多，内存积累的数据也就越多，那么输出的文件数也就会变少，比如上边的时间从10s增加为100s，那么一个小时的文件数量就会减少到1152个。但别高兴太早，实时业务能等那么久吗，本来人家10s看到结果更新一次，现在要等快两分钟，是人都会骂娘。所以这种方法适用的场景是消息实时到达，但不想挤压在一起处理，因为挤压在一起处理的话，批处理任务在干等，这时就可以采用这种方法。

    Coalesce大法好: 文章开头讲了，小文件的基数是 batch_number * partition_number，而第一种方法是减少 batch_number，那么这种方法就是减少 partition_number 了，这个 api 不细说，就是减少初始的分区个数。看过 spark 源码的童鞋都知道，对于窄依赖，一个子 RDD 的 partition 规则继承父 RDD，对于宽依赖(就是那些个叉叉叉ByKey操作)，如果没有特殊指定分区个数，也继承自父 rdd。那么初始的 SourceDstream 是几个 partiion，最终的输出就是几个 partition。所以 Coalesce 大法的好处就是，可以在最终要输出的时候，来减少一把 partition 个数。但是这个方法的缺点也很明显，本来是32个线程在写256M数据，现在可能变成了4个线程在写256M数据，而没有写完成这256M数据，这个 batch 是不算结束的。那么一个 batch 的处理时延必定增长，batch 挤压会逐渐增大。

    Spark Streaming 外部来处理: 我们既然把数据输出到 hdfs，那么说明肯定是要用 Hive 或者 Spark Sql 这样的“sql on hadoop”系统类进一步进行数据分析，而这些表一般都是按照半小时或者一小时、一天，这样来分区的(注意不要和 Spark Streaming 的分区混淆，这里的分区，是用来做分区裁剪优化的)，那么我们可以考虑在 Spark Streaming 外再启动定时的批处理任务来合并 Spark Streaming 产生的小文件。这种方法不是很直接，但是却比较有用，“性价比”较高，唯一要注意的是，批处理的合并任务在时间切割上要把握好，搞不好就可能会去合并一个还在写入的 Spark Streaming 小文件。

    自己调用 foreach 去 append: Spark Streaming 提供的 foreach 这个 outout 类 api （一种 Action 操作），可以让我们自定义输出计算结果的方法。那么我们其实也可以利用这个特性，那就是每个 batch 在要写文件时，并不是去生成一个新的文件流，而是把之前的文件打开。考虑这种方法的可行性，首先，HDFS 上的文件不支持修改，但是很多都支持追加，那么每个 batch 的每个 partition 就对应一个输出文件，每次都去追加这个 partition 对应的输出文件，这样也可以实现减少文件数量的目的。这种方法要注意的就是不能无限制的追加，当判断一个文件已经达到某一个阈值时，就要产生一个新的文件进行追加了。所以大概就是一直32个文件。

18,Spark经常说的repartition是个什么玩意
    增加或减少RDD的并行度.shuffle重新分配数据,如果减少分区数可以考虑使用coalesce,这样可以避免执行shuffle
    减少分区数目的:1,避免小文件;2,减少task个数;3,但是会增加task处理的数据量

19,Spark Streaming Duration微批处理
    sparkStreaming批处理的时间间隔,每个Batch Duration时间提交一次job,如果job的处理时间超过batch duration,会使得
    job无法按时提交,随着时间推移,越来越多的作业被拖延,最后导致整个sparkStreaming作业被阻塞,无法做到实时处理数据

20,如何区分Application和Driver
    Application是指用户编写的spark应用程序,包含驱动程序Driver和分布在集群中多个节点上运行的Executor代码,在执行过程中
    由一个或多个作业组成

    Driver是Spark中的Driver负责准备Spark应用程序的运行环境,负责与Master通信,进行资源申请,任务的分配和监控。当
    Executor部分运行完毕后,Driver负责把sc关闭。

21,介绍下Spark的通信方式
    Spark启动过程主要是Master和Worker之间的通信,首先由Worker节点向Master发送注册消息,然后Master处理完毕后,返回
    注册成功或失败的消息,如果注册成功,Worker会定时发送心跳信息给Master

22,Spark的存储体系
   Spark的存储体系是由各个Driver和Executor实例中的BlockManager所组成,但是从一个整体来看,把各个节点的BlockManager
   看成存储体系的一部分,那存储体系就有更多衍生的内容,比如块传输服务,map任务输出跟踪器,shuffle管理器等

23,说说Spark的特点,相对于MR来说
   1,减少磁盘IO，MR会把map端将中间输出和结果存储在磁盘中,reduce端又需要从磁盘读写中间结果,势必造成磁盘IO成为瓶颈
   。Spark允许将map端的中间结果输出和结果存储在内存中,reduce端在拉取中间结果的时候避免了大量的磁盘IO
   2,增加并行度,由于把中间结果写到磁盘与从磁盘读取中间结果属于不同的缓解,Hadoop将他们简单的串行执行衔接起来,Spark则
   把不同的环节抽象成为Stage，允许多个Stage既可以串行又可以并行
   3,避免重复计算,当Stage中某个分区的task执行失败后,会重新对此stage进行调度,但在重新调度的时候会过滤已经执行成功的
   分区任务,所以不会造成重复计算和资源浪费
   4,可选的shuffle排序,MR在shuffle之前有着固定的排序操作,而Spark则可以根据不同的场景选择在map端排序还是reduce排序
   5,灵活的内存管理策略,Spark将内存分为堆上的存储内存,堆外的存储内存,堆上的执行内存，堆外的执行内存4个部分

24,说说spark Narroe Depdency的分类
    OneToOneDependency
    RangeDependency

25,Task和Stage的分类
    Task指具体的执行任务,一个Job在每个Stage内都会按照RDD的partition数量,创建多个task，task分为shuffleMapTask和
    ResultTask两种。ShuffleMapTask和ResultTask类似于Hadoop中的Map任务和Reduce任务

26,总述Spark架构
    从集群部署的角度看,Spark集群由ClusterManager,Worker，Ececutor，Driver，Application组成
    ClusterManager:主要负责集群资源的分配和管理,CluserManager在YARN部署模式下为RM，Standalone模式下为Master
        CM分配的资源属于一级分配,它将各个Worker上的内存,CPU等资源分配给Application,但是不负责对Executor的资源分类。
        Standalone模式下Master会直接给Application分配内存,cpu和Executor等资源
    Worker:Spark的工作节点在yarn部署模式下实际由NodeManager替代,Worker节点主要负责把自己的内存和CPU等资源通过注册
        机制告知CM，创建Executor,把资源和任务进一步分配给Executor,同步资源信息,Executor状态信息给Application等等
        Stabdalone模式下,Master将Worker上的内存,cpu以及Executor等资源分配给Application后,将命令Worker启动
        CoarseGrainExecutorBackend进程(该进程会创建Executor实例)
    Executor:执行计算任务的一线组件,主要负责任务的执行以及与Worker Driver信息同步.
        Driver:Application的驱动程序,Application通过Driver与CM以及Executor进行通信.Driver可以运行在Application中,
        也可以由Application提交给CM并由CM安排Worker运行
    Application：Application通过Spark API进行RDD的转换和DAG的创建,并通过Driver将Application注册到CM，CM将会根据
        Application的资源需求,通过一级资源分配将Executor，内存,CPU等资源分配给Application.Driver会通过二级资源分配
        将Executor等资源分配给每一个任务,Application最后通过Driver告诉Executor运行任务

27,谈谈Spark Streaming Driver端重启会发生什么?
    1,恢复计算:使用检查点信息重启Driver端,重构上下文并重启接收器
    2,恢复元数据块:为了保证能够继续下去所必备的全部元数据块都被恢复
    3,未完成作业的重新形成:由于失败而没有处理完成的批处理,将使用恢复的元数据再次产生RDD和对应的作业
    4,读取保存在日志中的块数据:在这些作业执行的时候,块数据直接从预写日志中读出,这将恢复在日志中可靠
        地保存所有必要的数据
    5,重发尚未确认的数据:失败时没有保存到日志中的缓存数据将由数据源再次发送

28,StreamingContext启动时序图
    1,初始化StreamingContext中的DSreamGraph和JobScheduler，进而启动JobScheduler的ReceiveTracker和JobGenerator
    2,初始化阶段会进行成员变量的初始化,重要的包括DStreamGraph(包含DStream之间相互依赖的有向无环图)，
    JobScheduler(定时查看DStreamGraph,然后根据流入的数据生成作业),StreamTab(在SparkStreaming运行的时候对流数据处理的监控)
    3,然后就是创建InputStream,接着就是对InputStream进行flatMap,map等操作，类似于RDD的转换操作
    4,启动JobScheduler,实例化并启动ReceiverTracker和JobGenerator








